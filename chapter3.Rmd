```{r}
date()
```
# Chapter 3. Analysis exercise Logistic regression

## 2. Reading the data and  describing the dataset

```{r}
alc <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/alc.csv", sep = ",", header = TRUE)

colnames(alc)
```
The dataset explores student achievement in secondary education of two Portuguese schools. The data was collected using school reports and questionnaires. The performance in mathematics and portuguese language have been measudred and in addition the data included attributes such as demographic, social and school related features. In the dataset
variable 'alc_use' is the average of 'Dalc' and 'Walc'variables. 'high_use' is TRUE if 'alc_use' is higher than 2 and FALSE otherwise.

More detailed description of the dataset can be read at: https://archive.ics.uci.edu/ml/datasets/Student+Performance

Some of the answers are binary (eg. yes/no), and others numeric (eg. on a scale of 1-5) or nominal (eg. mother/father/other)


## 3. Relationships between alcohol consumption and other variables

I chose four variables: studytime, activities, health, goout

* I hypothesize that if alcohol consumption is high, then a student would spend less time studying
* I hypopthesize that if a student takes extra-curricular acitivities, their alcohol consumption is lower
* I hypothesize that if students alcohol consumption is high, they rate their current health status as worse
* I hypothesize that if students alcohol consumption is high, they go out with friends more 


## 4. Exploring the distributions of the variables
Comment on your findings and compare the results of your exploration to your previously stated hypotheses.

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(gmodels)

## Cross tabulations
CrossTable(alc$high_use, alc$studytime)
CrossTable(alc$high_use, alc$activities)
CrossTable(alc$high_use, alc$health)
CrossTable(alc$high_use, alc$goout)
```
## Bar plots
```{r}
studytime_barplot <- ggplot(data = alc, aes(x=studytime, fill = high_use))
studytime_barplot + geom_bar(position=position_dodge()) + labs(y="Number of students")

```
```{r}
activities_barplot <- ggplot(data = alc, aes(x=activities, fill = high_use))
activities_barplot + geom_bar(position=position_dodge()) + labs(y="Number of students")
```
```{r}
health_barplot <- ggplot(data = alc, aes(x=health, fill = high_use))
health_barplot + geom_bar(position=position_dodge()) + labs(y="Number of students")
```
```{r}
goout_barplot <- ggplot(data = alc, aes(x=goout, fill = high_use))
goout_barplot + geom_bar(position=position_dodge()) + labs(y="Number of students")
```
## Box plots

```{r}
studytime_boxplot <- ggplot(alc, aes(x = high_use, y = studytime))

# define the plot as a boxplot and draw it
studytime_boxplot + geom_boxplot() 
```
```{r}
activities_boxplot <- ggplot(alc, aes(x = high_use, y = activities))

activities_boxplot + geom_boxplot() 

```
Boxplot makes no sense in this case as activities is a binary variable

```{r}
health_boxplot <- ggplot(alc, aes(x = high_use, y = health))

health_boxplot + geom_boxplot() 
```
```{r}
goout_boxplot <- ggplot(alc, aes(x = high_use, y = goout))

goout_boxplot + geom_boxplot() 
```
There seems to be an association between high_use and goout variables as well as high_use and studytime supporting my initial hypotheses. There doesn't seem to be an association between health and amount alcohol use and activities and alcohol use.  

## 5. Logistic regression

### Presenting and interpreting summary of the fitted model
Fitting the model
```{r}
m <- glm(high_use ~ studytime + activities + health + goout, data = alc, family = "binomial")
summary(m)
```
The variables I thought were associated with high_use (studytime and goout) based on visual observation seem to be statistically significant as well based on this summary. For studytime there seems to be a negative association with high_use, meaning if the alcohol use is high, the probability of studying less is higher. High alcol use and going out with friends seem to be positively associated meaning that if the alcohol use is high, the probability of going more out with friends is higher. 

###Presenting and interpreting the coefficients of the model as odds ratios
```{r}
# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m)%>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI) 
```
In activities and health the confidence interval crosses 1, which means there is no association 
If the alcohol use is high, the probability of going out with friends is 2,14x higher. So none of the variables has very high odds ratio. 

## 6. Exploring the predictive power of my model

```{r}
 # fit the model
m <- glm(high_use ~ studytime + goout, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

library(dplyr)
# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% addmargins()

```

This means that my model of two statistically significant variables is not great at predicting high alcohol use. Other predictors would need to be added to create more accurate prediction. Among all predictions 91 were inaccurate. 

### Computing the training error

```{r}
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
```
```{r}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = nrow(alc))

# average number of wrong predictions in the cross validation
cv$delta[1]
```
This tells that 25% of predictions are wrong in this model. Of my hypotheses 50% were wrong, so this model does better than my original guesses. I do not know how to compare this with R with a random guess. 

## 7. BONUS

```{r}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = nrow(alc))

# average number of wrong predictions in the cross validation
cv$delta[1]
#10-fold cross validation
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv$delta[1]
```
My model is slightly better than the model introduced in the exercise set. 
